{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded imports\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import keras\n",
    "import joblib\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "print \"loaded imports\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALB\n",
      "BET\n",
      "DOL\n",
      "LAG\n",
      "NoF\n",
      "OTHER\n",
      "SHARK\n"
     ]
    }
   ],
   "source": [
    "#load images\n",
    "folders = [d for d in listdir(\"./train/\") if not isfile(join(\"./train/\", d)) and d not in [\"cropped\"]]\n",
    "\n",
    "training_data = np.array([])\n",
    "training_labels = np.array([])\n",
    "\n",
    "for category in folders:\n",
    "    print category\n",
    "    images = [file for file in listdir(\"./train/\"+category)]\n",
    "    np.random.shuffle(images)\n",
    "    images = images[0:300] #limit number of images used\n",
    "    \n",
    "    for image in images:\n",
    "        hog = cv2.HOGDescriptor()\n",
    "        img = cv2.imread(\"./train/\" + category + \"/\" + image, 0)\n",
    "        img = cv2.resize(img, (400, 250))\n",
    "        h = hog.compute(img)\n",
    "        h = h.astype(np.float64)\n",
    "        np.random.shuffle(h)\n",
    "        h = h[0:100,:] # trim vector so all are same size\n",
    "        vector_data = h.reshape(1,100) \n",
    "        \n",
    "        if len(training_data) == 0:\n",
    "            training_data = np.append(training_data, vector_data)\n",
    "            training_data = training_data.reshape(1,100)\n",
    "        else:\n",
    "            training_data   = np.concatenate((training_data, vector_data), axis=0)\n",
    "        training_labels = np.append(training_labels,category)\n",
    "        \n",
    "print \"finished\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = training_data\n",
    "y = training_labels\n",
    "y = y.reshape(y.shape[0],)\n",
    "\n",
    "# Create and fit the SVM\n",
    "# Fitting should take a few minutes\n",
    "clf = SVC(kernel='linear', C = 1.0, probability=True)\n",
    "clf.fit(X,y)\n",
    "joblib.dump(clf, 'fishy_svm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Prediction:\n",
      "['SHARK']\n",
      "[[ 0.1382508   0.15924064  0.14877601  0.09481978  0.13919176  0.16176548\n",
      "   0.15795553]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['fishy_svm.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf = joblib.load('fishy_svm.pkl') # uncomment to use generated\n",
    "fishPredict = cv2.imread('./train/LAG/img_00657.jpg', 0)  # Correct is LAG --> Class 3\n",
    "hog = cv2.HOGDescriptor()\n",
    "fishPredict = cv2.resize(fishPredict, (400, 250))\n",
    "h = hog.compute(fishPredict)\n",
    "h = h.astype(np.float64)\n",
    "np.random.shuffle(h)\n",
    "h = h[0:100,:] # trim vector so all are same size\n",
    "vector_data = h.reshape(1,100)\n",
    "\n",
    "print(\"Linear SVM Prediction:\")\n",
    "print(clf.predict(vector_data))        # prints highest probability class, only\n",
    "print(clf.predict_proba(vector_data))\n",
    "\n",
    "joblib.dump(clf, 'fishy_svm.pkl')\n",
    "    # to load SVM model, use:  clf = joblib.load('filename.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = joblib.load('fishy_svm.pkl')\n",
    "hog = cv2.HOGDescriptor()\n",
    "def getPrediction(filename):\n",
    "    fish_image = cv2.imread(filename, 0)\n",
    "    fish_image = cv2.resize(fish_image, (400, 250))\n",
    "    fish_h = hog.compute(fish_image)\n",
    "    fish_h = fish_h.astype(np.float64)\n",
    "    np.random.shuffle(fish_h)\n",
    "    fish_h = fish_h[0:100,:]\n",
    "    vector_data = fish_h.reshape(1,100)\n",
    "    return clf.predict_proba(vector_data)\n",
    "\n",
    "def savePredictions():\n",
    "    headers = [\"image\", \"ALB\", \"BET\", \"DOL\", \"LAG\", \"NoF\", \"OTHER\", \"SHARK\", \"YFT\"]\n",
    "    predictions = np.array([])\n",
    "    maxi = 0;\n",
    "    for file in listdir(\"./test_stg1/\"):\n",
    "        if maxi > 0:\n",
    "            continue\n",
    "        else:\n",
    "            maxi +=1\n",
    "        prediction = getPrediction(\"./test_stg1/\"+file)\n",
    "        prediction = np.insert(prediction, 0, 0)\n",
    "        prediction_s = np.array(prediction, dtype='|S4')\n",
    "        print prediction_s\n",
    "        prediction_s = np.insert(prediction_s, 0, file)\n",
    "        print prediction_s\n",
    "        np.append(predictions, prediction_s)\n",
    "        continue\n",
    "    \n",
    "    df = pd.DataFrame(predictions, columns=headers)\n",
    "    df.to_csv('test.csv', index=False, header=True, sep=',')\n",
    "    \n",
    "savePredictions()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
