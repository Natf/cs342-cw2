{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.91705914019\n",
      "0.630098784225\n",
      "Epoch 1/20\n",
      "900/900 [==============================] - 0s - loss: 0.5247     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/20\n",
      "900/900 [==============================] - 0s - loss: 0.4849     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/20\n",
      "900/900 [==============================] - 0s - loss: 0.3900     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/20\n",
      "900/900 [==============================] - 0s - loss: 0.2895     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/20\n",
      "900/900 [==============================] - 0s - loss: 0.2799     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/20\n",
      "900/900 [==============================] - 0s - loss: 0.2603     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/20\n",
      "900/900 [==============================] - 0s - loss: 0.2635     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/20\n",
      "900/900 [==============================] - 0s - loss: 0.2626     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/20\n",
      "900/900 [==============================] - 0s - loss: 0.2582     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/20\n",
      "900/900 [==============================] - 0s - loss: 0.2563     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 11/20\n",
      "900/900 [==============================] - 0s - loss: 0.2588     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 12/20\n",
      "900/900 [==============================] - 0s - loss: 0.2521     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 13/20\n",
      "900/900 [==============================] - 0s - loss: 0.2589     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 14/20\n",
      "900/900 [==============================] - 0s - loss: 0.2593     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 15/20\n",
      "900/900 [==============================] - 0s - loss: 0.2558     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 16/20\n",
      "900/900 [==============================] - 0s - loss: 0.2524     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 17/20\n",
      "900/900 [==============================] - 0s - loss: 0.2557     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 18/20\n",
      "900/900 [==============================] - 0s - loss: 0.2533     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 19/20\n",
      "900/900 [==============================] - 0s - loss: 0.2429     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 20/20\n",
      "900/900 [==============================] - 0s - loss: 0.2522     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "100/100 [==============================] - 0s\n",
      "[0.24665483832359314]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score as cv\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "'''\n",
    "    Please note that these are example solutions - they are not the best models for the data\n",
    "    To get better models, feature engineering is required - e.g. considering feature selection, \n",
    "    normalisation and the use of powers.\n",
    "    These examples are to help you get code working, but you will need to look at model parameters\n",
    "    to make sure that effective models are built that do not overfit etc\n",
    "'''\n",
    "\n",
    "\n",
    "def predictTNA(df,tLabel):\n",
    "    mlp = MLPRegressor(hidden_layer_sizes=(10,10)) #other parameters -- ,activation = 'logistic')\n",
    "    Y = df[tLabel]\n",
    "    X = df.drop(tLabel,axis=1).copy()\n",
    "\n",
    "    #k_fold = KFold(n_splits=10)\n",
    "    #scores = []\n",
    "    #for train,test in k_fold.split(X):\n",
    "    #    mlp = mlp.fit(X.iloc[train],Y.iloc[train])\n",
    "    #    s = mlp.score(X.iloc[test],Y.iloc[test])\n",
    "    #    scores.append(s)\n",
    "    #print scores\n",
    "    predicted = cross_val_predict(mlp,X,Y,cv=10)\n",
    "    print r2_score(Y,predicted)\n",
    "\n",
    "\n",
    "def predictClass(df,tLabel):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(10,10))\n",
    "    Y = df[tLabel]\n",
    "    X = df.drop(tLabel,axis=1).copy()\n",
    "    predicted = cross_val_predict(mlp,X,Y,cv=10)\n",
    "    print roc_auc_score(Y,predicted) \n",
    "\n",
    "def predictKerasClass(df,tLabel):\n",
    "    Y = df[tLabel]\n",
    "    X = df.drop(tLabel,axis=1).copy()\n",
    "    \n",
    "    #create model with 2 hidden layers of 10 units, and an output layer\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10,input_dim=13,init='uniform',activation='relu'))\n",
    "    model.add(Dropout(0.2)) #this randomly sets some input units to 0 - prevents overfitting\n",
    "    model.add(Dense(10,init='uniform'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1,init='normal'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "    k_fold = KFold(n_splits=10)\n",
    "    scores = []\n",
    "    #just one iteration of kFold CV\n",
    "    for train,test in k_fold.split(X):\n",
    "        model.fit(X.iloc[train].as_matrix(),Y.iloc[train].as_matrix(),nb_epoch=20, batch_size=100)\n",
    "        s = model.evaluate(X.iloc[test].as_matrix(),Y.iloc[test].as_matrix(),batch_size=100)\n",
    "        scores.append(s)\n",
    "        break\n",
    "    print scores\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "probeA = pd.read_csv('probeA.csv',header = 0)\n",
    "dfClass = pd.read_csv('classA.csv',header=0)\n",
    "probeA['class'] = dfClass\n",
    "#task1: predict TNA\n",
    "predictTNA(probeA,\"TNA\")\n",
    "#an example of a better MLP for this task has a logistic activation function\n",
    "\n",
    "#task2: predict class\n",
    "predictClass(probeA,'class')\n",
    "#an example of a better MLP for this task has 4 hidden layers with 10 units per layer\n",
    "\n",
    "#task3: using keras\n",
    "predictKerasClass(probeA,'class')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
